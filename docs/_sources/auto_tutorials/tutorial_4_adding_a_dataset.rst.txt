
.. DO NOT EDIT.
.. THIS FILE WAS AUTOMATICALLY GENERATED BY SPHINX-GALLERY.
.. TO MAKE CHANGES, EDIT THE SOURCE PYTHON FILE:
.. "auto_tutorials/tutorial_4_adding_a_dataset.py"
.. LINE NUMBERS ARE GIVEN BELOW.

.. only:: html

    .. note::
        :class: sphx-glr-download-link-note

        Click :ref:`here <sphx_glr_download_auto_tutorials_tutorial_4_adding_a_dataset.py>`
        to download the full example code

.. rst-class:: sphx-glr-example-title

.. _sphx_glr_auto_tutorials_tutorial_4_adding_a_dataset.py:


====================================
Tutorial 4: Creating a dataset class
====================================

.. GENERATED FROM PYTHON SOURCE LINES 6-23

.. code-block:: default

    # Authors: Pedro L. C. Rodrigues, Sylvain Chevallier
    #
    # https://github.com/plcrodrigues/Workshop-MOABB-BCI-Graz-2019

    import mne
    import numpy as np
    from pyriemann.classification import MDM
    from pyriemann.estimation import Covariances
    from scipy.io import loadmat, savemat
    from sklearn.pipeline import make_pipeline

    from moabb.datasets import download as dl
    from moabb.datasets.base import BaseDataset
    from moabb.evaluations import WithinSessionEvaluation
    from moabb.paradigms import LeftRightImagery









.. GENERATED FROM PYTHON SOURCE LINES 24-33

Creating some Data
------------------

To illustrate the creation of a dataset class in MOABB, we first create an
example dataset saved in .mat file. It contains a single fake recording on
8 channels lasting for 150 seconds (sampling frequency 256 Hz). We have
included the script that creates this dataset and have uploaded it online.
The fake dataset is available on the
`Zenodo website <https://sandbox.zenodo.org/record/369543>`_

.. GENERATED FROM PYTHON SOURCE LINES 33-70

.. code-block:: default



    def create_example_dataset():
        """Create a fake example for a dataset"""
        sfreq = 256
        t_recording = 150
        t_trial = 1  # duration of a trial
        intertrial = 2  # time between end of a trial and the next one
        n_chan = 8

        x = np.zeros((n_chan + 1, t_recording * sfreq))  # electrodes + stimulus
        stim = np.zeros(t_recording * sfreq)
        t_offset = 1.0  # offset where the trials start
        n_trials = 40

        rep = np.linspace(0, 4 * t_trial, t_trial * sfreq)
        signal = np.sin(2 * np.pi / t_trial * rep)
        for n in range(n_trials):
            label = n % 2 + 1  # alternate between class 0 and class 1
            tn = int(t_offset * sfreq + n * (t_trial + intertrial) * sfreq)
            stim[tn] = label
            noise = 0.1 * np.random.randn(n_chan, len(signal))
            x[:-1, tn : (tn + t_trial * sfreq)] = label * signal + noise
        x[-1, :] = stim
        return x, sfreq


    # Create the fake data
    for subject in [1, 2, 3]:
        x, fs = create_example_dataset()
        filename = "subject_" + str(subject).zfill(2) + ".mat"
        mdict = {}
        mdict["x"] = x
        mdict["fs"] = fs
        savemat(filename, mdict)









.. GENERATED FROM PYTHON SOURCE LINES 71-86

Creating a Dataset Class
------------------------

We will create now a dataset class using the fake data simulated with the
code from above. For this, we first need to import the right classes from
MOABB:

- ``dl`` is a very useful script that downloads automatically a dataset online
  if it is not yet available in the user's computer. The script knows where
  to download the files because we create a global variable telling the URL
  where to fetch the data.
- ``BaseDataset`` is the basic class that we overload to create our dataset.

The global variable with the dataset's URL should specify an online
repository where all the files are stored.

.. GENERATED FROM PYTHON SOURCE LINES 86-89

.. code-block:: default


    ExampleDataset_URL = "https://sandbox.zenodo.org/record/369543/files/"








.. GENERATED FROM PYTHON SOURCE LINES 90-96

The ``ExampleDataset`` needs to implement only 3 functions:

- ``__init__`` for indicating the parameter of the dataset
- ``_get_single_subject_data`` to define how to process the data once they
  have been downloaded
- ``data_path`` to define how the data are downloaded.

.. GENERATED FROM PYTHON SOURCE LINES 96-145

.. code-block:: default



    class ExampleDataset(BaseDataset):
        """
        Dataset used to exemplify the creation of a dataset class in MOABB.
        The data samples have been simulated and has no physiological meaning
        whatsoever.
        """

        def __init__(self):
            super().__init__(
                subjects=[1, 2, 3],
                sessions_per_subject=1,
                events={"left_hand": 1, "right_hand": 2},
                code="Example dataset",
                interval=[0, 0.75],
                paradigm="imagery",
                doi="",
            )

        def _get_single_subject_data(self, subject):
            """return data for a single subject"""
            file_path_list = self.data_path(subject)

            data = loadmat(file_path_list[0])
            x = data["x"]
            fs = data["fs"]
            ch_names = ["ch" + str(i) for i in range(8)] + ["stim"]
            ch_types = ["eeg" for i in range(8)] + ["stim"]
            info = mne.create_info(ch_names, fs, ch_types)
            raw = mne.io.RawArray(x, info)

            sessions = {}
            sessions["session_1"] = {}
            sessions["session_1"]["run_1"] = raw
            return sessions

        def data_path(
            self, subject, path=None, force_update=False, update_path=None, verbose=None
        ):
            """Download the data from one subject"""
            if subject not in self.subject_list:
                raise (ValueError("Invalid subject number"))

            url = "{:s}subject_0{:d}.mat".format(ExampleDataset_URL, subject)
            path = dl.data_dl(url, "ExampleDataset")
            return [path]  # it has to return a list









.. GENERATED FROM PYTHON SOURCE LINES 146-151

Using the ExampleDataset
------------------------

Now that the `ExampleDataset` is defined, it could be instanciated directly.
The rest of the code follows the steps described in the previous tutorials.

.. GENERATED FROM PYTHON SOURCE LINES 151-166

.. code-block:: default


    dataset = ExampleDataset()

    paradigm = LeftRightImagery()
    X, labels, meta = paradigm.get_data(dataset=dataset, subjects=[1])

    evaluation = WithinSessionEvaluation(
        paradigm=paradigm, datasets=dataset, overwrite=False, suffix="newdataset"
    )
    pipelines = {}
    pipelines["MDM"] = make_pipeline(Covariances("oas"), MDM(metric="riemann"))
    scores = evaluation.process(pipelines)

    print(scores)





.. rst-class:: sphx-glr-script-out

 .. code-block:: none

      0%|                                              | 0.00/2.77M [00:00<?, ?B/s]      1%|▍                                     | 32.8k/2.77M [00:00<00:11, 235kB/s]      3%|█▏                                    | 81.9k/2.77M [00:00<00:08, 303kB/s]      7%|██▌                                    | 180k/2.77M [00:00<00:05, 486kB/s]     11%|████▍                                  | 311k/2.77M [00:00<00:03, 664kB/s]     19%|███████▍                               | 524k/2.77M [00:00<00:02, 972kB/s]     27%|██████████▎                           | 754k/2.77M [00:00<00:01, 1.20MB/s]     36%|█████████████▌                        | 983k/2.77M [00:00<00:01, 1.34MB/s]     44%|████████████████▏                    | 1.21M/2.77M [00:01<00:01, 1.43MB/s]     52%|███████████████████▎                 | 1.44M/2.77M [00:01<00:00, 1.50MB/s]     60%|██████████████████████▎              | 1.67M/2.77M [00:01<00:00, 1.54MB/s]     69%|█████████████████████████▍           | 1.90M/2.77M [00:01<00:00, 1.57MB/s]     77%|████████████████████████████▌        | 2.13M/2.77M [00:01<00:00, 1.59MB/s]     85%|███████████████████████████████▌     | 2.36M/2.77M [00:01<00:00, 1.60MB/s]     94%|██████████████████████████████████▋  | 2.59M/2.77M [00:01<00:00, 1.61MB/s]      0%|                                              | 0.00/2.77M [00:00<?, ?B/s]    100%|█████████████████████████████████████| 2.77M/2.77M [00:00<00:00, 4.53GB/s]
    Example dataset-WithinSession:   0%|          | 0/3 [00:00<?, ?it/s]    Example dataset-WithinSession:  33%|###3      | 1/3 [00:00<00:00,  7.70it/s]
      0%|                                              | 0.00/2.77M [00:00<?, ?B/s]
      1%|▍                                     | 32.8k/2.77M [00:00<00:11, 229kB/s]
      3%|█▏                                    | 81.9k/2.77M [00:00<00:09, 295kB/s]
      4%|█▌                                     | 115k/2.77M [00:00<00:10, 264kB/s]
      8%|███                                    | 213k/2.77M [00:00<00:05, 429kB/s]
     15%|█████▊                                 | 410k/2.77M [00:00<00:03, 765kB/s]
     23%|████████▌                             | 623k/2.77M [00:00<00:02, 1.01MB/s]
     31%|███████████▋                          | 852k/2.77M [00:01<00:01, 1.20MB/s]
     39%|██████████████▍                      | 1.08M/2.77M [00:01<00:01, 1.32MB/s]
     47%|█████████████████▌                   | 1.31M/2.77M [00:01<00:01, 1.40MB/s]
     56%|████████████████████▌                | 1.54M/2.77M [00:01<00:00, 1.45MB/s]
     64%|███████████████████████▋             | 1.77M/2.77M [00:01<00:00, 1.49MB/s]
     72%|██████████████████████████▋          | 2.00M/2.77M [00:01<00:00, 1.52MB/s]
     81%|█████████████████████████████▊       | 2.23M/2.77M [00:01<00:00, 1.54MB/s]
     89%|████████████████████████████████▉    | 2.46M/2.77M [00:02<00:00, 1.55MB/s]
     97%|███████████████████████████████████▉ | 2.69M/2.77M [00:02<00:00, 1.56MB/s]
      0%|                                              | 0.00/2.77M [00:00<?, ?B/s]    100%|█████████████████████████████████████| 2.77M/2.77M [00:00<00:00, 3.71GB/s]
    Example dataset-WithinSession:  67%|######6   | 2/3 [00:03<00:02,  2.01s/it]
      0%|                                              | 0.00/2.77M [00:00<?, ?B/s]
      1%|▍                                     | 32.8k/2.77M [00:00<00:11, 228kB/s]
      3%|█▏                                    | 81.9k/2.77M [00:00<00:09, 294kB/s]
      4%|█▌                                     | 115k/2.77M [00:00<00:10, 264kB/s]
      8%|███                                    | 213k/2.77M [00:00<00:05, 429kB/s]
     12%|████▊                                  | 344k/2.77M [00:00<00:04, 601kB/s]
     20%|███████▊                               | 557k/2.77M [00:00<00:02, 897kB/s]
     28%|██████████▊                           | 786k/2.77M [00:01<00:01, 1.12MB/s]
     37%|█████████████▌                       | 1.02M/2.77M [00:01<00:01, 1.27MB/s]
     45%|████████████████▋                    | 1.25M/2.77M [00:01<00:01, 1.37MB/s]
     53%|███████████████████▋                 | 1.47M/2.77M [00:01<00:00, 1.43MB/s]
     62%|██████████████████████▊              | 1.70M/2.77M [00:01<00:00, 1.48MB/s]
     70%|█████████████████████████▊           | 1.93M/2.77M [00:01<00:00, 1.51MB/s]
     78%|████████████████████████████▉        | 2.16M/2.77M [00:01<00:00, 1.53MB/s]
     87%|████████████████████████████████     | 2.39M/2.77M [00:02<00:00, 1.54MB/s]
     95%|███████████████████████████████████  | 2.62M/2.77M [00:02<00:00, 1.56MB/s]
      0%|                                              | 0.00/2.77M [00:00<?, ?B/s]    100%|█████████████████████████████████████| 2.77M/2.77M [00:00<00:00, 3.91GB/s]
    Example dataset-WithinSession: 100%|##########| 3/3 [00:06<00:00,  2.62s/it]    Example dataset-WithinSession: 100%|##########| 3/3 [00:06<00:00,  2.27s/it]
       score      time  samples  ... n_sessions          dataset  pipeline
    0    1.0  0.013167     40.0  ...          1  Example dataset       MDM
    1    1.0  0.013078     40.0  ...          1  Example dataset       MDM
    2    1.0  0.020835     40.0  ...          1  Example dataset       MDM

    [3 rows x 9 columns]




.. GENERATED FROM PYTHON SOURCE LINES 167-174

Pushing on MOABB Github
-----------------------

If you want to make your dataset available to everyone, you could upload
your data on public server (like Zenodo or Figshare) and signal that you
want to add your dataset to MOABB in the  `dedicated issue <https://github.com/NeuroTechX/moabb/issues/1>`_.  # noqa: E501
You could then follow the instructions on `how to contribute <https://github.com/NeuroTechX/moabb/blob/master/CONTRIBUTING.md>`_  # noqa: E501


.. rst-class:: sphx-glr-timing

   **Total running time of the script:** ( 0 minutes  10.186 seconds)


.. _sphx_glr_download_auto_tutorials_tutorial_4_adding_a_dataset.py:

.. only:: html

  .. container:: sphx-glr-footer sphx-glr-footer-example


    .. container:: sphx-glr-download sphx-glr-download-python

      :download:`Download Python source code: tutorial_4_adding_a_dataset.py <tutorial_4_adding_a_dataset.py>`

    .. container:: sphx-glr-download sphx-glr-download-jupyter

      :download:`Download Jupyter notebook: tutorial_4_adding_a_dataset.ipynb <tutorial_4_adding_a_dataset.ipynb>`


.. only:: html

 .. rst-class:: sphx-glr-signature

    `Gallery generated by Sphinx-Gallery <https://sphinx-gallery.github.io>`_
